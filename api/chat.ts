import { resumeKnowledge, resumePromptContext } from './resumeData.js'
import { buildMockAnswer } from './hrAssistant.js'
import { classifyIntent, IntentResult, getIntentLabel } from './intentRouter.js'
import { retrieveRelevantChunks, formatChunksForPrompt } from './ragRetriever.js'

export const config = { runtime: 'nodejs', maxDuration: 60 }

type ChatMessage = {
  role: 'system' | 'user' | 'assistant'
  content: string
}

function json(res: any, status: number, data: unknown) {
  res.statusCode = status
  res.setHeader('Content-Type', 'application/json; charset=utf-8')
  res.end(JSON.stringify(data))
}

function getClientIp(req: any) {
  const forwarded = req.headers?.['x-forwarded-for']
  if (typeof forwarded === 'string' && forwarded.length > 0) return forwarded.split(',')[0].trim()
  const realIp = req.headers?.['x-real-ip']
  if (typeof realIp === 'string' && realIp.length > 0) return realIp
  return req.socket?.remoteAddress || 'unknown'
}

function applyRateLimit(req: any) {
  const ip = getClientIp(req)
  const now = Date.now()
  const windowMs = 60_000
  const maxRequests = 30

  const g: any = globalThis as any
  if (!g.__resumeChatRateLimit) g.__resumeChatRateLimit = new Map<string, number[]>()
  const store: Map<string, number[]> = g.__resumeChatRateLimit

  const arr = store.get(ip) || []
  const kept = arr.filter((t) => now - t < windowMs)
  kept.push(now)
  store.set(ip, kept)

  if (kept.length > maxRequests) {
    return {
      ok: false as const,
      retryAfterSeconds: Math.ceil((windowMs - (now - kept[0])) / 1000),
    }
  }
  return { ok: true as const }
}

function clampText(s: unknown, maxLen: number) {
  if (typeof s !== 'string') return ''
  return s.length > maxLen ? s.slice(0, maxLen) : s
}

function buildBasePrompt(redactContact: boolean) {
  const contactLine = redactContact
    ? 'æ³¨æ„ï¼šä¸è¦è¾“å‡ºå€™é€‰äººçš„æ‰‹æœºå·/é‚®ç®±ç­‰è”ç³»æ–¹å¼ï¼›è‹¥ç”¨æˆ·æ˜Žç¡®ç´¢è¦ï¼Œè¯·è¯´æ˜Ž"é»˜è®¤å¼€å¯è„±æ•"ï¼Œå¼•å¯¼å…¶å…³é—­è„±æ•åŽå†è¯¢é—®ã€‚'
    : `è”ç³»æ–¹å¼ï¼ˆä»…åœ¨ç”¨æˆ·æ˜Žç¡®ç´¢è¦æ—¶è¾“å‡ºï¼‰ï¼šç”µè¯ ${resumeKnowledge.contact.phone}ï¼Œé‚®ç®± ${resumeKnowledge.contact.email}ã€‚`

  return [
    'ä½ æ˜¯"å€™é€‰äººï¼šåˆ˜ç”Ÿæ°"çš„åœ¨çº¿ç®€åŽ†åŠ©æ‰‹ï¼Œé¢å‘ HR/é¢è¯•å®˜é—®ç­”ã€‚',
    '',
    'ã€æ ¸å¿ƒè§„åˆ™ã€‘',
    '1. åŸºäºŽç®€åŽ†äº‹å®žè¿›è¡Œåˆç†æŽ¨è®ºï¼ˆå¦‚ï¼šä»Ž"æ—¥å‡å·¥ä½œ10å°æ—¶"å¯æŽ¨å¯¼å‡º"æŠ—åŽ‹èƒ½åŠ›å¼º"ï¼‰',
    '2. ç¡®å®žæ— æ³•å›žç­”çš„é—®é¢˜ï¼Œæ‰è¯´"ç®€åŽ†æœªæä¾›è¯¥ä¿¡æ¯"',
    '3. ç¦æ­¢è¾“å‡ºä»»ä½• Markdown æ ¼å¼ç¬¦å·ï¼ˆå¦‚ **åŠ ç²—**ã€# æ ‡é¢˜ã€- åˆ—è¡¨ï¼‰ï¼Œåªç”¨çº¯æ–‡æœ¬',
    '4. ç”¨ âœ“ ç¬¦å·ä»£æ›¿ - ä½œä¸ºåˆ—è¡¨ç¬¦å·',
    '5. ' + contactLine,
    '',
    'ã€ç®€åŽ†ä¿¡æ¯ã€‘',
    resumePromptContext,
  ].join('\n')
}

// Prompt é£Žæ ¼æ¨¡æ¿
const PROMPT_STYLES = {
  concise: `
ã€è¾“å‡ºé£Žæ ¼ - æžç®€çº¯æ–‡æœ¬ã€‘
ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š
1. æ€»å­—æ•° â‰¤ 120 å­—ï¼Œç»å¯¹ç¦æ­¢è¶…è¿‡ 150 å­—
2. æœ€å¤š 3-4 ä¸ªè¦ç‚¹ï¼Œæ¯ç‚¹ â‰¤ 15 å­—
3. ç¦æ­¢ä½¿ç”¨ä»»ä½• Markdownï¼šç¦æ­¢ ** # - [ ] \`\`\` ç­‰ç¬¦å·
4. åªç”¨çº¯æ–‡æœ¬ + âœ“ ç¬¦å·
5. æ ¼å¼ï¼šä¸€å¥è¯ç»“è®º + æ¢è¡Œ + âœ“ è¦ç‚¹1 + æ¢è¡Œ + âœ“ è¦ç‚¹2...
6. ç¤ºä¾‹ï¼š
å€™é€‰äººåŒ¹é…åº¦è¾ƒé«˜
âœ“ 2å¹´Bç«¯äº§å“ç»éªŒ
âœ“ 211ç¡•å£«å­¦åŽ†
âœ“ æœ‰AIè½åœ°é¡¹ç›®`,

  star: `
ã€è¾“å‡ºé£Žæ ¼ã€‘
- ä½¿ç”¨ STAR ç»“æž„è¯¦ç»†å±•å¼€
- S: æƒ…å¢ƒèƒŒæ™¯ï¼ˆé¡¹ç›®èƒŒæ™¯/ä¸šåŠ¡ç—›ç‚¹ï¼‰
- T: ä»»åŠ¡ç›®æ ‡ï¼ˆä½ çš„èŒè´£/ç›®æ ‡ï¼‰
- A: é‡‡å–çš„è¡ŒåŠ¨ï¼ˆå…·ä½“åšäº†ä»€ä¹ˆï¼‰
- R: å–å¾—çš„ç»“æžœï¼ˆé‡åŒ–æˆæžœï¼‰`,

  rag_enhanced: (ragContext: string) => `
${ragContext}

ã€è¾“å‡ºè¦æ±‚ã€‘
- ä¼˜å…ˆåŸºäºŽä»¥ä¸Šã€ç›¸å…³ææ–™ã€‘å›žç­”
- å¯å¼•ç”¨ç¼–å·å¦‚ [1][2]
- å¦‚ææ–™ä¸è¶³ï¼Œç»“åˆç®€åŽ†ä¿¡æ¯è¡¥å……`
}

/**
 * æž„å»ºå¢žå¼ºç‰ˆ Promptï¼ˆåŸºäºŽæ„å›¾è·¯ç”±å’Œ RAGï¼‰
 */
function buildEnhancedPrompt(
  redactContact: boolean,
  intent: IntentResult,
  userQuestion: string
): string {
  const base = buildBasePrompt(redactContact)

  if (intent.suggestedPromptStyle === 'concise') {
    return base + PROMPT_STYLES.concise
  }

  if (intent.suggestedPromptStyle === 'star') {
    return base + PROMPT_STYLES.star
  }

  if (intent.suggestedPromptStyle === 'rag_enhanced') {
    const results = retrieveRelevantChunks(userQuestion, {
      projectFilter: intent.projectName,
      topK: 3,
    })
    const ragContext = formatChunksForPrompt(results)

    if (ragContext) {
      return base + PROMPT_STYLES.rag_enhanced(ragContext)
    }
    return base + PROMPT_STYLES.concise
  }

  return base + PROMPT_STYLES.concise
}

// ä¿ç•™æ—§å‡½æ•°ç”¨äºŽå…¼å®¹
function buildSystemPrompt(redactContact: boolean) {
  return buildBasePrompt(redactContact) + PROMPT_STYLES.concise
}

async function parseBody(req: any) {
  if (req.body && typeof req.body === 'object') return req.body
  const chunks: Buffer[] = []
  for await (const chunk of req) chunks.push(Buffer.from(chunk))
  const raw = Buffer.concat(chunks).toString('utf8')
  if (!raw) return {}
  try {
    return JSON.parse(raw)
  } catch {
    return {}
  }
}

export default async function handler(req: any, res: any) {
  const origin = req.headers?.origin
  if (origin) res.setHeader('Vary', 'Origin')
  res.setHeader('Access-Control-Allow-Origin', origin || '*')
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type')
  res.setHeader('Cache-Control', 'no-store')

  if (req.method === 'OPTIONS') {
    res.statusCode = 204
    res.end()
    return
  }

  if (req.method !== 'POST') {
    json(res, 405, { error: 'Method Not Allowed' })
    return
  }

  const limited = applyRateLimit(req)
  if (!limited.ok) {
    res.setHeader('Retry-After', String(limited.retryAfterSeconds))
    json(res, 429, { error: 'Too Many Requests', retryAfterSeconds: limited.retryAfterSeconds })
    return
  }

  const body = await parseBody(req)
  const redactContact = Boolean(body?.redactContact)
  const wantStream = Boolean(body?.stream) || String(req.headers?.accept || '').includes('text/event-stream')
  const inputMessages = Array.isArray(body?.messages) ? (body.messages as any[]) : []
  const messages: ChatMessage[] = []
  for (const m of inputMessages.slice(-12)) {
    const role = m?.role
    if (role !== 'user' && role !== 'assistant') continue
    const content = clampText(m?.content, 2000)
    if (!content) continue
    messages.push({ role, content })
  }
  if (messages.length === 0 || messages[messages.length - 1].role !== 'user') {
    json(res, 400, { error: 'Invalid messages' })
    return
  }

  const apiKey = process.env.LLM_API_KEY
  const model = process.env.LLM_MODEL || 'gpt-4o-mini'
  const baseUrl = (process.env.LLM_BASE_URL || 'https://api.openai.com/v1').replace(/\/$/, '')

  // ðŸ”¥ æ„å›¾è¯†åˆ« + RAG å¢žå¼º
  const lastUserMessage = messages[messages.length - 1]?.content || ''
  const intent = classifyIntent(lastUserMessage)

  // è°ƒè¯•æ—¥å¿—ï¼ˆç”Ÿäº§çŽ¯å¢ƒå¯ç§»é™¤ï¼‰
  console.log(`[Intent] ${intent.intent} (${intent.confidence}) | keywords: ${intent.matchedKeywords.join(', ')}`)

  if (!apiKey) {
    const reply = buildMockAnswer(lastUserMessage, redactContact)
    if (wantStream) {
      res.statusCode = 200
      res.setHeader('Content-Type', 'text/event-stream; charset=utf-8')
      res.setHeader('Cache-Control', 'no-cache, no-transform')
      res.setHeader('Connection', 'keep-alive')
      res.setHeader('X-Accel-Buffering', 'no')
      res.flushHeaders?.()
      const write = (event: string | null, data: any) => {
        if (event) res.write(`event: ${event}\n`)
        res.write(`data: ${typeof data === 'string' ? data : JSON.stringify(data)}\n\n`)
      }
      write('open', { ok: true, mode: 'mock', intent: { type: intent.intent, label: getIntentLabel(intent.intent) } })
      write(null, { delta: reply })
      write('done', { done: true })
      res.end()
      return
    }
    json(res, 200, { reply, mode: 'mock', intent: { type: intent.intent, label: getIntentLabel(intent.intent) } })
    return
  }

  // ä½¿ç”¨å¢žå¼ºç‰ˆ Promptï¼ˆå¸¦æ„å›¾å’Œ RAGï¼‰
  const systemPrompt = buildEnhancedPrompt(redactContact, intent, lastUserMessage)
  const payload = {
    model,
    temperature: 0.2,
    messages: [{ role: 'system', content: systemPrompt }, ...messages],
    stream: wantStream ? true : undefined,
  }

  async function fetchWithTimeoutRetry(url: string, init: any, opts: { timeoutMs: number; maxRetries: number }) {
    let attempt = 0
    while (true) {
      const controller = new AbortController()
      const t = setTimeout(() => controller.abort(), opts.timeoutMs)
      try {
        const resp = await fetch(url, { ...init, signal: controller.signal })
        clearTimeout(t)
        if (resp.status >= 500 && resp.status < 600 && attempt < opts.maxRetries) {
          attempt++
          continue
        }
        return resp
      } catch (e) {
        clearTimeout(t)
        if (attempt < opts.maxRetries) {
          attempt++
          continue
        }
        throw e
      }
    }
  }

  let upstream: Response
  try {
    const candidates = (() => {
      const list: string[] = []
      const add = (m: string) => {
        if (!m) return
        if (list.includes(m)) return
        list.push(m)
      }
      add(model)
      if (baseUrl.includes('generativelanguage.googleapis.com')) {
        add('gemini-2.0-flash')
        add('gemini-3-flash-preview')
        add('gemini-1.5-flash')
      }
      return list
    })()

    let last: Response | null = null
    for (const m of candidates) {
      const nextPayload = { ...payload, model: m }
      last = await fetchWithTimeoutRetry(
        `${baseUrl}/chat/completions`,
        {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            Authorization: `Bearer ${apiKey}`,
          },
          body: JSON.stringify(nextPayload),
        },
        { timeoutMs: wantStream ? 30000 : 20000, maxRetries: 1 }
      )
      if (last.status !== 404) break
    }
    upstream = last as Response
  } catch {
    json(res, 502, { error: 'Failed to reach LLM upstream' })
    return
  }

  if (wantStream) {
    res.statusCode = 200
    res.setHeader('Content-Type', 'text/event-stream; charset=utf-8')
    res.setHeader('Cache-Control', 'no-cache, no-transform')
    res.setHeader('Connection', 'keep-alive')
    res.setHeader('X-Accel-Buffering', 'no')
    res.flushHeaders?.()
    const write = (event: string | null, data: any) => {
      if (event) res.write(`event: ${event}\n`)
      res.write(`data: ${typeof data === 'string' ? data : JSON.stringify(data)}\n\n`)
    }
    if (!upstream.ok || !upstream.body) {
      const ua = upstream.headers.get('retry-after')
      const status = upstream.status
      const err =
        status === 401
          ? { error: 'LLM unauthorized' }
          : status === 429
            ? { error: 'LLM rate limited', retryAfterSeconds: ua ? Number(ua) || undefined : undefined }
            : { error: 'LLM upstream error' }
      write('error', err)
      res.end()
      return
    }
    write('open', { ok: true, intent: { type: intent.intent, label: getIntentLabel(intent.intent) } })
    const decoder = new TextDecoder('utf-8')
    let buffer = ''
    try {
      for await (const chunk of upstream.body as any) {
        buffer += decoder.decode(chunk, { stream: true })
        const lines = buffer.split(/\r?\n/)
        buffer = lines.pop() || ''
        for (const line of lines) {
          const trimmed = line.trim()
          if (!trimmed.startsWith('data:')) continue
          const payloadLine = trimmed.slice(5).trim()
          if (payloadLine === '[DONE]') {
            write('done', { done: true })
            res.end()
            return
          }
          try {
            const obj = JSON.parse(payloadLine)
            const delta =
              obj?.choices?.[0]?.delta?.content ??
              obj?.choices?.[0]?.text ??
              ''
            if (delta) write(null, { delta })
          } catch {
            // ignore parse errors
          }
        }
      }
    } catch {
      write('error', { error: 'Upstream stream broken' })
    }
    write('done', { done: true })
    res.end()
    return
  }

  const text = await upstream.text()
  if (!upstream.ok) {
    const ua = upstream.headers.get('retry-after')
    const status = upstream.status
    if (status === 401) {
      json(res, 401, { error: 'Unauthorized to LLM', detail: text.slice(0, 2000) })
      return
    }
    if (status === 429) {
      if (ua) res.setHeader('Retry-After', ua)
      json(res, 429, { error: 'LLM rate limited', detail: text.slice(0, 2000), retryAfterSeconds: ua ? Number(ua) || undefined : undefined })
      return
    }
    json(res, 502, { error: 'LLM upstream error', status, detail: text.slice(0, 2000) })
    return
  }

  let data: any
  try {
    data = JSON.parse(text)
  } catch {
    json(res, 502, { error: 'Invalid upstream response' })
    return
  }

  const reply =
    data?.choices?.[0]?.message?.content ??
    data?.choices?.[0]?.text ??
    ''

  if (!reply || typeof reply !== 'string') {
    json(res, 502, { error: 'Empty reply from upstream' })
    return
  }

  json(res, 200, {
    reply,
    model: data?.model || model,
    usage: data?.usage,
    intent: {
      type: intent.intent,
      label: getIntentLabel(intent.intent),
      confidence: intent.confidence,
    },
  })
}
